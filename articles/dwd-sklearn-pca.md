---
title: "scikit-learn ã® PCA ã§ GPU ã‚’æ´»ç”¨ã™ã‚‹"
emoji: "ğŸ“ˆ"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Python", "æ©Ÿæ¢°å­¦ç¿’"]
published: true
---

# ç›®çš„

[Scikit-learnãŒå®Ÿé¨“çš„ã«GPUå¯¾å¿œã—ã¦ã„ãŸã®ã§èª¿æŸ»ã—ã¦ã¿ãŸï¼](https://qiita.com/fujine/items/6c997a073fec5bcea512) ã¨ã„ã†è‰¯è¨˜äº‹ãŒã‚ã£ã¦ã€ä¸€éƒ¨åˆ† `scikit-learn` ã§ GPU ã‚’æ´»ç”¨ã§ãã‚‹ã‚ˆã†ãªã®ã§ PCA (ä¸»æˆåˆ†åˆ†æ) ã‚’è©¦ã—ã¦ã¿ãŸã„ã€‚

# ã©ã®ãã‚‰ã„å¯¾å¿œã—ã¦ã„ã‚‹ï¼Ÿ

[11.1. Array API support (experimental)](https://scikit-learn.org/stable/modules/array_api.html) ã‚’è¦‹ã‚‹ã¨ `LinearDiscriminantAnalysis` ä»¥å¤–ã«ã‚‚ `decomposition.PCA` ã‚‚ã„ã‘ãã†ãªã®ã§ã€ä»Šå›ã¯ã“ã‚Œã‚’ Google Colab ä¸Šã® T4 ã§è©¦ã™ã€‚

# å®Ÿè£…

ã¾ãšã¯ã€å¾“æ¥é€šã‚Šã« CPU ã§è©¦ã—ã¦ã€æ¬¡ã« PyTorch ã® Tensor ã‚’çªã£è¾¼ã‚“ã§ã¿ã‚‹ã¨ã„ã†å½¢ã‚’ã¨ã‚‹ã€‚

ä»¥ä¸‹ã§æœ€æ–°ã® `scikit-learn` ã¨ã€GPU ã‚’æ´»ç”¨ã™ã‚‹æ™‚ã«å¿…è¦ã«ãªã‚‹ `array-api-compat` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚

```python
%%bash

pip install -qU "scikit-learn>=1.4.0" array-api-compat
```

æ¬¡ã«å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ import ã™ã‚‹ã€‚

```python
from __future__ import annotations

import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn import config_context
from sklearn.decomposition import PCA
import torch
from torch.utils.data import Subset
import torchvision
import torchvision.transforms as transforms
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä½•ã§ã‚‚è‰¯ã„ã®ã ãŒã€ä»Šå›ã¯ [QMNIST](https://github.com/facebookresearch/qmnist) ã‚’ä½¿ã£ã¦æ•°å­—ã®ã€Œ0ã€ã¨ã€Œ1ã€ã®ãƒ‡ãƒ¼ã‚¿ã§ PCA ã—ã¦ã¿ã‚‹ã€‚

```python
root = os.path.join(os.getenv('HOME'), '.torch')

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5)
])

dataset = torchvision.datasets.QMNIST(
    root=root, 
    train=True,
    download=True,
    transform=transform
)

indices = []
for i, target in enumerate(dataset.targets):
    target = int(target[0])
    if target == 0 or target == 1:
        indices.append(i)

zero_one_dataset = Subset(dataset, indices)
print(len(zero_one_dataset))
```

> 12665

ãŠæ‰‹é ƒãªã‚µã‚¤ã‚ºæ„Ÿã§ã‚ã‚‹ã€‚

## CPU ç‰ˆ

ã¾ãšã¯ CPU ã§è©¦ã™ã®ã§ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã‚’ã™ã‚‹ã€‚

```python
data = np.array([tensor[0].numpy().flatten()
                for tensor in zero_one_dataset], dtype=float)
labels = [tensor[1] for tensor in zero_one_dataset]

print(data.shape)
```

> (12665, 784)

ä»¥ä¸‹ã§ PCA ã‚’å®Ÿè¡Œã€‚å¯è¦–åŒ–ã—ãŸã„ã®ã§ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•°ã‚’ 2 ã¨ã™ã‚‹ã€‚

```python
%%time

pca = PCA(n_components=2)
pca.fit(data)
data_pca = pca.transform(data)
```

> CPU times: user 1.06 s, sys: 202 ms, total: 1.26 s
> Wall time: 680 ms

ã»ã¼ä¸€ç¬ã§å®Œäº†ã€‚çµæœã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚

```python
x_z = []
y_z = []
x_o = []
y_o = []
for i, (dat, label) in enumerate(zip(data_pca, labels)):
    if i >= 100:
        break
    if label == 0:
        x_z.append(dat[0])
        y_z.append(dat[1])
    else:
        x_o.append(dat[0])
        y_o.append(dat[1])

plt.figure()
plt.scatter(x_z, y_z, c="r")
plt.scatter(x_o, y_o, c="b")
plt.xlabel("component-1")
plt.ylabel("component-2")
plt.show()
```

![](/images/dwd-sklearn-pca/001.png)

ç‰¹ã«é©šãã‚‚ãªã„çµæœã‚’å¾—ãŸã€‚$x=0$ ãã‚‰ã„ã§å¢ƒç•Œç·šã‚’å¼•ã„ãŸã‚‰åˆ†é›¢ã§ãã‚‹ã‹ãªã¨ã„ã†æ„Ÿã˜ã€‚

## GPU ç‰ˆ

ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ã‚’ PyTorch ã® `Tensor` ã«ã™ã‚‹ã€‚

```python
data2 = torch.asarray(data, device="cuda", dtype=torch.float32)
```

æ¬¡ã« [11.1. Array API support (experimental)](https://scikit-learn.org/stable/modules/array_api.html) ã‚’å‚è€ƒã« `PCA` ã‚’ä½¿ã†ã€‚

>  (with `svd_solver="full"`, `svd_solver="randomized"` and `power_iteration_normalizer="QR"`)

ã¨æ›¸ã„ã¦ã‚ã‚‹ã®ã«ã§ã“ã‚Œã«æ³¨æ„ã™ã‚‹ã€‚`svd_solver="randomized"` ã®ã»ã†ãŒé€Ÿã„ã®ã§ã“ã‚Œã‚’ä½¿ã£ã¦ã¿ãŸã€‚

```python
%%time

with config_context(array_api_dispatch=True):
    pca2 = PCA(n_components=2, svd_solver="randomized",
               power_iteration_normalizer="QR")
    pca2.fit(data2)
    data_pca2 = pca2.transform(data2)
```

> CPU times: user 17.9 ms, sys: 0 ns, total: 17.9 ms
> Wall time: 18.7 ms

CPU ã§ 680 ms ã ã£ãŸã‚‚ã®ãŒã€20 ms å‰å¾Œã«ãªã£ãŸã®ã§ã€ä»–ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚é€Ÿããªã‚Šãã†ãªæ°—ãŒã™ã‚‹ã€‚

å¿µã®ãŸã‚ã«å¯è¦–åŒ–ã™ã‚‹ã€‚

```python
x_z = []
y_z = []
x_o = []
y_o = []
for i, (dat, label) in enumerate(zip(data_pca2.cpu().numpy(), labels)):
    if i >= 100:
        break
    if label == 0:
        x_z.append(dat[0])
        y_z.append(dat[1])
    else:
        x_o.append(dat[0])
        y_o.append(dat[1])

plt.figure()
plt.scatter(x_z, y_z, c="r")
plt.scatter(x_o, y_o, c="b")
plt.xlabel("component-1")
plt.ylabel("component-2")
plt.show()
```

![](/images/dwd-sklearn-pca/002.png)

CPU ç‰ˆã¨ã®é•ã„ã¯ç›®è¦–ã§ã¯åˆ†ã‹ã‚‰ãªã„ã€‚

# ã¾ã¨ã‚

`scikit-learn` ãŒä¸€éƒ¨ GPU ã«å¯¾å¿œã—ãŸãã€ã‚„ã£ãŸï½ï¼ã¨ã„ã†å†…å®¹ã€‚

`manifold.TSNE` ã¯ã¾ã ã‚‰ã—ã„ã€‚[tsne-cuda](https://github.com/CannyLab/tsne-cuda) ã¨ã„ã†ã®ãŒã‚ã£ã¦ã“ã‚Œã‚‚ä½¿ã„ã‚„ã™ã‹ã£ãŸã®ã ãŒã€

> We only support `n_components=2`. We currently have no plans to support more dimensions as this requires significant changes to the code to accomodate.

ã¨ã‚ã‚‹ã®ã§æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
