---
title: "Stable Diffusion ã§éŠã‚“ã§ã¿ã‚‹ (5) â€” ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©¦ã™ï¼ˆå®Ÿè£…ç·¨ï¼‰"
emoji: "ğŸ¨"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Python", "æ©Ÿæ¢°å­¦ç¿’", "stablediffusion"]
published: false
---

# ç›®çš„

ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã€‚Stable Diffusion ã®ä¸­ã§ã©ã†ä½¿ã‚ã‚Œã¦ã€æ™®é€šã®ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã©ã†é•ã†ã®ã‹ãŒçŸ¥ã‚ŠãŸã„ã¨ã„ã†ã‚‚ã®ã€‚

ã“ã‚Œã«ã¤ã„ã¦ [Stable Diffusion ã§éŠã‚“ã§ã¿ã‚‹ (4) â€” ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©¦ã™ï¼ˆãªã‚“ã¡ã‚ƒã£ã¦ç†è«–ç·¨ï¼‰](/derwind/articles/dwd-stable-diffusion04) ã§è«–æ–‡æƒ…å ±ã«ã¤ã„ã¦ã¾ã¨ã‚ãŸã®ã§ã€Diffuser ã‚’ä½¿ã£ãŸå‹•ãã«ã¤ã„ã¦è¦‹ãŸã„ã€‚

**æœ€çµ‚çš„ã«ã¯è«–æ–‡ã«å¯¾å¿œã™ã‚‹ä»¥ä¸‹ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’è¦‹ã‚‹ã®ãŒç›®çš„**ã§ã‚ã‚‹:

$$
\begin{align*}
\hat{\epsilon}_\theta (\mathbf{x}_t, c (s), t) = (1 + w) \epsilon_\theta (\mathbf{x}_t, c (p_+), t) - w \epsilon_\theta (\mathbf{x}_t, c (p_-), t)
\end{align*}
$$

â€» ä»Šå›ã€ä½µã›ã¦ Texual Inversion ã‚‚çœºã‚ãŸãŸã‚æ–‡ç« é‡ãŒç›¸å½“ã«å¤šããªã£ã¦ã—ã¾ã£ãŸãƒ»ãƒ»ãƒ»ã€‚

# Counterfeit-V3.0 ã¨ EasyNegativeV2

[gsdf/Counterfeit-V3.0](https://huggingface.co/gsdf/Counterfeit-V3.0) ãŒ `EasyNegative` ã¨ã„ã† â€œã‚·ã‚§ãƒ•ã®ãŠã‚¹ã‚¹ãƒ¡â€ ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†ã¨ä¸€ç·’ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãªã®ã§ã€ã“ã‚Œã‚’ä½¿ã£ã¦ã¿ãŸã„ã€‚`model_index.json` ãŒä½•æ•…ã‹ç½®ã„ã¦ã„ãªã„ã®ã§ã€ä½¿ãŠã†ã¨ã™ã‚‹ã¨ä¸€æ‰‹é–“å¿…è¦ã§ã‚ã‚‹ã€‚

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã¾ãšä»¥ä¸‹ã®ã‚ˆã†ã« `.safetensors` ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚`Counterfeit-V3.0_fix_fp16.safetensors` ã§ã‚‚è‰¯ã•ãã†ãªæ°—ãŒã™ã‚‹ã—ã€ã“ã¡ã‚‰ã®ã»ã†ãŒå°ã•ã„ã®ã§å¥½ã¿ã§ã€‚

```sh
$ mkdir ~/.cache/huggingface/hub/models--gsdf--Counterfeit-V3.0
$ cd ~/.cache/huggingface/hub/models--gsdf--Counterfeit-V3.0
$ curl -LO https://huggingface.co/gsdf/Counterfeit-V3.0/resolve/main/Counterfeit-V3.0_fp16.safetensors
```

## ä½¿ã„æ–¹

æ™®é€šã«ä½¿ã†ã€‚

```python
from __future__ import annotations

import os
from pathlib import Path

import torch
from diffusers import StableDiffusionPipeline


hub_dir = Path(os.getenv("HOME"))/".cache/huggingface/hub"
model = str(hub_dir/"models--gsdf--Counterfeit-V3.0/Counterfeit-V3.0_fp16.safetensors")

pipe = StableDiffusionPipeline.from_single_file(
    model,
    torch_dtype=torch.float16
).to("cuda")

# EasyNegativeV2 ã‚’ä½¿ã„ãŸã„å ´åˆ
pipe.load_textual_inversion(
    "gsdf/Counterfeit-V3.0",
    weight_name="embedding/EasyNegativeV2.safetensors", 
    token="EasyNegativeV2"
)

prompt = "girl eating pizza"
negative_prompt = None
#negative_prompt="EasyNegativeV2, extra fingers, fewer fingers"

#generator = None
# seed ã‚’å›ºå®šã—ãŸã„å ´åˆ
generator = torch.Generator()
generator.manual_seed(1234)

result = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=512,
    height=512,
    num_inference_steps=50,
    generator=generator,
)

display(result.images[0])
```

![](/images/dwd-stable-diffusion05/001.png =256x)

ä¸Šè¨˜ã§ã¯ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦ã„ãªã„ãŒã€

```python
negative_prompt="EasyNegativeV2, extra fingers, fewer fingers"
```

ã‚’æŒ‡å®šã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ã€‚ä½•æ•…ãƒ”ã‚¶ãŒå¤§ãããªã‚‹ã®ã‹ã¯ã•ã¦ç½®ãã€ä½•ã ã‹é«˜è§£åƒåº¦æ„ŸãŒå‡ºãŸã€‚

![](/images/dwd-stable-diffusion05/002.png =256x)

ã“ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä¸€ä½“ä½•ã‚’é˜»æ­¢ã—ã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿã¨ã„ã†ã“ã¨ã§ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å†…å®¹ã‚’å…¥ã‚Œã¦ã¿ã‚ˆã†ã€‚

```python
prompt = "girl eating pizza, EasyNegativeV2"
```

![](/images/dwd-stable-diffusion05/003.png =256x)

ãŠå¯Ÿã—ãã ã•ã„ãƒ»ãƒ»ãƒ»ã¨ã„ã†çµæœã§ã‚ã‚‹ã€‚

# Texutual Inversion

ãªã‚‹ã»ã©ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœã¯ä½•ã¨ãªãåˆ†ã‹ã£ãŸãŒã€æŒ‡å®šã—ã¦ã„ã‚‹ã€ŒEasyNegativeV2ã€ã¯ä¸€ä½“å…¨ä½“ã©ã†ã—ã¦ 3 ã¤ç›®ã®ã‚ˆã†ãªçµµã®ç”Ÿæˆã‚’æŠ‘åˆ¶ã§ãã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿæˆ‘ã€…ã¯ã€ŒEasyNegativeV2ã€ã¨ã„ã†å˜èªã‚’è¦‹ã¦ãã‚Œã‚’ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ãã‚‹ã®ã ã‚ã†ã‹ï¼Ÿãã“ã§å‡ºã¦æ¥ã‚‹ã®ãŒ â€œTexutual Inversionâ€[^1] ã§ã‚ã‚‹ã€‚

[^1]: é€šå¸¸ã¯ãƒ†ã‚­ã‚¹ãƒˆ â†’ ç”»åƒã ã¨æ€ã†ã®ã§ã€ç”»åƒ â†’ ãƒ†ã‚­ã‚¹ãƒˆã®æ–¹å‘ãªã®ã§ inversion ã¨ã„ã†ã¨ã“ã‚ã ã‚ã†ã‹ã€‚GAN inversion[^2] ã«ãƒ’ãƒ³ãƒˆã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã ã€‚

[^2]: GAN ã‚¤ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ (GAN inversion) ã¨ã¯ã€äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸæ•µå¯¾çš„ç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (GAN) ã®æ½œåœ¨ç©ºé–“ã«ç”»åƒã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚‹ã€‚ç°¡å˜ã«è¨€ã†ã¨ã€ç‰¹å®šã®å®Ÿç”»åƒã«å¯¾ã—ã¦ã€GANã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’é€šã—ã¦ç”Ÿæˆã•ã‚Œã‚‹ç”»åƒãŒå…ƒã®ç”»åƒã¨éå¸¸ã«ä¼¼ã¦ã„ã‚‹ã‚ˆã†ãªæ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆGANã®å…¥åŠ›ç©ºé–“ã§ã®è¡¨ç¾ï¼‰ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã‚’æŒ‡ã™ã€‚(by ChatGPT-4o)

arXiv:2208.01618 [An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion](https://arxiv.org/abs/2208.01618) ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ç”»åƒå…¥åŠ›ã‹ã‚‰æ¦‚å¿µã®ãƒˆãƒ¼ã‚¯ãƒ³ $S_*$ ã‚’ä½œã‚‹ã¨ã„ã†æŠ€è¡“ãŒã‚ã‚‹ã€‚å®Ÿéš›ã«ã¯ã€ä»Šå›ã¯é˜»æ­¢ã—ãŸã„ â€œä½•ã‹â€ ã‚’åŸ‹ã‚è¾¼ã‚“ã ãƒ†ãƒ³ã‚½ãƒ« (embedding) ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã®å¯¾ã§ã‚ã‚‹æ—¢è£½ã®ã€ŒEasyNegativeV2ã€ã‚’ç”¨ã„ãŸå½¢ã«ãªã‚‹ã€‚

ã“ã®æŠ€è¡“ã‚’ç”¨ã„ã‚‹ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã“ã®æ¦‚å¿µã«å¯¾å¿œã™ã‚‹ embedding ãŒå‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã“ã® embedding ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã®ç´ã¥ã‘ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ãŒ `DiffusionPipeline.load_textual_inversion` ã§ã‚ã‚Šã€Diffusers ã§ã¯ `TextualInversionLoaderMixin` ã¨ã„ã†ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³ã®å½¢ã§æ©Ÿèƒ½ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚

## StableDiffusionPipeline.load_textual_inversion

`load_textual_inversion` ã§ã€ŒEasyNegativeV2ã€ã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ãŸã®ã ãŒã€è©²å½“ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã¯ [diffusers/loaders/textual_inversion.py#L267-L461](https://github.com/huggingface/diffusers/blob/v0.29.2/src/diffusers/loaders/textual_inversion.py#L267-L461) ã§ã‚ã‚‹ã€‚

ã€Œ# 7.4 Load token and embeddingã€ã®è¾ºã‚ŠãŒé‡è¦ãã†ã ã€‚

```python
    def load_textual_inversion(
        self,
        pretrained_model_name_or_path: Union[str, List[str], Dict[str, torch.Tensor], List[Dict[str, torch.Tensor]]],
        token: Optional[Union[str, List[str]]] = None,
        tokenizer: Optional["PreTrainedTokenizer"] = None,  # noqa: F821
        text_encoder: Optional["PreTrainedModel"] = None,  # noqa: F821
        **kwargs,
    ):
        # 1. Set correct tokenizer and text encoder
        tokenizer = tokenizer or getattr(self, "tokenizer", None)
        text_encoder = text_encoder or getattr(self, "text_encoder", None)
        ...
        # 4. Load state dicts of textual embeddings
        state_dicts = load_textual_inversion_state_dicts(pretrained_model_name_or_paths, **kwargs)
        ...
        # 4. Retrieve tokens and embeddings
        tokens, embeddings = self._retrieve_tokens_and_embeddings(tokens, state_dicts, tokenizer)
        ...
        # 7.3 Increase token embedding matrix
        text_encoder.resize_token_embeddings(len(tokenizer) + len(tokens))
        input_embeddings = text_encoder.get_input_embeddings().weight
```

ï¼ˆä»¥ä¸‹ã®éƒ¨åˆ†ã«æ³¨ç›®ã—ãŸã„ï¼‰

```python
        # 7.4 Load token and embedding
        for token, embedding in zip(tokens, embeddings):
            # add tokens and get ids
            tokenizer.add_tokens(token)
            token_id = tokenizer.convert_tokens_to_ids(token)
            input_embeddings.data[token_id] = embedding
            logger.info(f"Loaded textual inversion embedding for {token}.")

        input_embeddings.to(dtype=dtype, device=device)
        ...
```

ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«ç™»éŒ²ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ ID ã‚’ç™ºè¡Œã•ã›ã€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ç®¡ç†ã™ã‚‹æƒ…å ±ã«ãŠã„ã¦ã€ã“ã®ãƒˆãƒ¼ã‚¯ãƒ³ ID ã®å ´æ‰€ã« embedding ã‚’ç™»éŒ²ã—ã¦ã„ã‚‹ã€‚

## å®Ÿé¨“

ä¸Šè¨˜ã‚’è¸ã¾ãˆã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦æ—¢çŸ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸€è¦§ã‚’å–å¾—ã§ãã‚‹ã€‚

```python
pipe = StableDiffusionPipeline.from_pretrained(...)  # or .from_single_file

tokenizer = pipe.tokenizer
for token_id in range(50):
    token = tokenizer.convert_ids_to_tokens(token_id)
    print(f"{token_id} -> {token}")
```

> 0 -> !
> 1 -> "
> 2 -> #
> 3 -> $
> 4 -> %
> 5 -> &
> 6 -> '
> 7 -> (
> 8 -> )
> 9 -> *
> ...

ã§æ—¢çŸ¥ã® ID ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã«æˆ»ã™ã¨ Unicode ã® Basic Latin ã® U+0021 ã®ç¯„å›²ãŒãšã‚‰ãšã‚‰å‡ºã¦æ¥ã‚‹ã€‚

`embedding` ã®ãƒ†ãƒ³ã‚½ãƒ«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ã§å–å¾—ã§ãã‚‹ã€‚

```python
embedding = pipe.text_encoder.get_input_embeddings().weight.data[token_id]
```

## EasyNegativeV2

æ—¢ã«ã¿ãŸã‚ˆã†ã« EasyNegativeV2 ã®å–ã‚Šè¾¼ã¿ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã™ã‚‹ã€‚

```python
pipe.load_textual_inversion(
    "gsdf/Counterfeit-V3.0",
    weight_name="embedding/EasyNegativeV2.safetensors", 
    token="EasyNegativeV2"
)
```

ã“ã‚Œã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`pipe.text_encoder.get_input_embeddings().weight.data` ã®ã‚µã‚¤ã‚ºãŒ `[49408, 768]` ã‹ã‚‰ `[49424, 768]` ã«å¤‰åŒ–ã™ã‚‹ã€‚

```python
tokenizer = pipe.tokenizer

for token_id in range(49408, 49424):
    token = tokenizer.convert_ids_to_tokens(token_id)
    print(f"{token_id} -> {token}")
```

> 49408 -> EasyNegativeV2
> 49409 -> EasyNegativeV2_1
> ...
> 49423 -> EasyNegativeV2_15

ãŒè¦‹ãˆã‚‹ã€‚ã‚ˆã£ã¦ã€`EasyNegativeV2` ã¯ 1ï½15 ã® 15 å€‹ã®æ¦‚å¿µã®è©°ã‚åˆã‚ã›ã®ã‚ˆã†ã«æ€ã‚ã‚Œã‚‹ã€‚ãã‚Œãã‚ŒãŒã©ã†ã„ã†æ¦‚å¿µã‹ã¯åˆ†ã‹ã‚‰ãªã„ãŒã€æ—¢ã«è¦‹ãŸçµµã§å‡¡ãã®å¯Ÿã—ã¯ã¤ãã€‚

# ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æŒ‡å®šã®è€ƒå¯Ÿ

ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æŒ‡å®šã«ã¤ã„ã¦è€ƒå¯Ÿã—ãŸã„ã€‚

ã“ã‚Œã‚‚æ—¢ã«è¦‹ãŸãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ä½¿ã†:

```python
prompt = "girl eating pizza"
negative_prompt="EasyNegativeV2, extra fingers, fewer fingers"

result = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=512,
    height=512,
    num_inference_steps=50,
)
```

ã“ã®ã“ã¨ã‹ã‚‰ã€`StableDiffusionPipeline.__call__` ã‚’è¦‹ã‚‹ã®ãŒè‰¯ã•ãã†ã ã¨åˆ†ã‹ã‚‹ã€‚[\_\_call\_\_](https://github.com/huggingface/diffusers/blob/v0.29.2/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L756-L1067) ã‚’è¦‹ã‚‹ã¨ã€

## StableDiffusionPipeline.\_\_call\_\_

```python
    def __call__(
        self,
        prompt: Union[str, List[str]] = None,
        height: Optional[int] = None,
        width: Optional[int] = None,
        num_inference_steps: int = 50,
        ...
        negative_prompt: Optional[Union[str, List[str]]] = None,
        ...
    ):
        ...
        # 3. Encode input prompt
        ...
        prompt_embeds, negative_prompt_embeds = self.encode_prompt(
            prompt,
            ...
            negative_prompt,
            ...
        )
        ...
```

ã¨ã„ã†æ„Ÿã˜ã«ãªã£ã¦ã„ã‚‹ã€‚æ¬¡ã« [encode_prompt](https://github.com/huggingface/diffusers/blob/v0.29.2/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L302-L482) ã‚’è¦‹ã‚ˆã†ã€‚

## StableDiffusionPipeline.encode_prompt

`prompt_embeds` ã¨ `negative_prompt_embeds` ãŒæ˜ç¤ºçš„ã«ä¸ãˆã‚‰ã‚Œã¦ã„ãªã„å ´åˆã«ã¯ã“ã‚Œã‚‰ã‚’ CLIP ã® `tokenizer` ã‚„ `text_encoder` ã‚’ç”¨ã„ã¦ä½œã‚Šå‡ºã™ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚

```python
    def encode_prompt(
        self,
        prompt,
        ...
        negative_prompt=None,
        prompt_embeds: Optional[torch.Tensor] = None,
        negative_prompt_embeds: Optional[torch.Tensor] = None,
        ...
    ):
        ...
        if prompt_embeds is None:
            # textual inversion: process multi-vector tokens if necessary
            if isinstance(self, TextualInversionLoaderMixin):
                prompt = self.maybe_convert_prompt(prompt, self.tokenizer)

            text_inputs = self.tokenizer(
                prompt,
                ...
            )
            text_input_ids = text_inputs.input_ids
            ...
            if clip_skip is None:
                prompt_embeds = self.text_encoder(text_input_ids.to(device), ...)
                ...
            ...

        # get unconditional embeddings for classifier free guidance
        if do_classifier_free_guidance and negative_prompt_embeds is None:
            if negative_prompt is None:
            ...
            elif isinstance(negative_prompt, str):
                uncond_tokens = [negative_prompt]
            ...
            uncond_input = self.tokenizer(
                uncond_tokens,
                ...
            )
            ...
            negative_prompt_embeds = self.text_encoder(
                uncond_input.input_ids.to(device),
                ...
            )
            negative_prompt_embeds = negative_prompt_embeds[0]
            ...
        return prompt_embeds, negative_prompt_embeds
```

ç‰¹ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ³¨ç›®ã—ã¦è¿½ã„ã‹ã‘ã‚‹ã¨ã€ã©ã†ã‚„ã‚‰ã€

- ãƒ†ãƒ³ã‚½ãƒ« `prompt_embeds` ã‚’ä¸ãˆã¦ãŠã‚‰ãšã€ã‹ã¤ `negative_prompt` ã‚‚ä¸ãˆã¦ã„ãªã„å ´åˆã¯ â€œç©ºæ–‡å­—åˆ—ã‚’ä½¿ã£ãŸãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆâ€ ãŒç”Ÿæˆã•ã‚Œã€
- ä¸ãˆã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯ `negative_prompt` ãŒ

`uncond_tokens` ã«æ ¼ç´ã•ã‚Œã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ãã—ã¦ã“ã‚Œã‚‰ãŒæœ€çµ‚çš„ã«ã¯ `negative_prompt_embeds` ã«å¤‰æ›ã•ã‚Œã¦è¿”ã•ã‚Œã‚‹ã€‚
ã“ã®è¾ºã¯ [Stable Diffusion ã§éŠã‚“ã§ã¿ã‚‹ (4) â€” ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©¦ã™ï¼ˆãªã‚“ã¡ã‚ƒã£ã¦ç†è«–ç·¨ï¼‰](/derwind/articles/dwd-stable-diffusion04) ã§è¦‹ãŸã€Eqs. (4) ã¨ (5) ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€ã“ã‚Œã‚‰ã«å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ã¤ã¾ã‚Šã€ã‚¯ãƒ©ã‚¹è­˜åˆ¥ã®åŸ‹ã‚è¾¼ã¿ã«ç©ºã‚’å…¥ã‚ŒãŸã‚‰ç„¡æ¡ä»¶ã€æ„å‘³ã®ã‚ã‚‹ã‚‚ã®ã‚’å…¥ã‚ŒãŸã‚‰ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãªã‚‹ã®ã§ã‚ã‚‹ã€‚

```python
    def encode_prompt(
        self,
        prompt,
        ...
        negative_prompt=None,
        prompt_embeds: Optional[torch.Tensor] = None,
        negative_prompt_embeds: Optional[torch.Tensor] = None,
        ...
    ):
        ...
        # get unconditional embeddings for classifier free guidance
        if do_classifier_free_guidance and negative_prompt_embeds is None:
            uncond_tokens: List[str]
            if negative_prompt is None:
                uncond_tokens = [""] * batch_size
            ...
            elif isinstance(negative_prompt, str):
                uncond_tokens = [negative_prompt]
            ...
            else:
                uncond_tokens = negative_prompt
            ...
            uncond_input = self.tokenizer(
                uncond_tokens,
                ...
            )
            ...
            negative_prompt_embeds = self.text_encoder(
                uncond_input.input_ids.to(device),
                ...
            )
            negative_prompt_embeds = negative_prompt_embeds[0]
            ...
        return prompt_embeds, negative_prompt_embeds
```

[\_\_call\_\_](https://github.com/huggingface/diffusers/blob/v0.29.2/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L756-L1067) ã®ç¶šãã‚’è¦‹ã‚‹ã¨ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯çµåˆã•ã‚Œã¦ã€ã€Œãƒã‚¤ã‚ºã‚’æ¨å®šã™ã‚‹ U-Netã€[^3]ã«å…¥åŠ›ã•ã‚Œã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚

[^3]: $\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ ã«å¯¾ã—ã¦ã€$\epsilon$ ã‚’æ¨å®šã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: $\epsilon_\theta (x_t, t)$ã€‚å…¥å‡ºåŠ›ãŒåŒã˜ã‚µã‚¤ã‚ºã®ãƒ†ãƒ³ã‚½ãƒ«ã«ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ U-Net ã§å®Ÿè£…ã•ã‚Œã‚‹ã®ãŒä¸»æµã®ã‚ˆã†ã§ã‚ã‚‹ã€‚

```python
    def __call__(
        self,
        prompt: Union[str, List[str]] = None,
        height: Optional[int] = None,
        width: Optional[int] = None,
        num_inference_steps: int = 50,
        ...
        negative_prompt: Optional[Union[str, List[str]]] = None,
        ...
    ):
        ...
        # 3. Encode input prompt
        ...
        prompt_embeds, negative_prompt_embeds = self.encode_prompt(
            prompt,
            ...
            negative_prompt,
            ...
        )

        # For classifier free guidance, we need to do two forward passes.
        # Here we concatenate the unconditional and text embeddings into a single batch
        # to avoid doing two forward passes
        if self.do_classifier_free_guidance:
            prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])
        ...
        # 7. Denoising loop
        ...
        with self.progress_bar(total=num_inference_steps) as progress_bar:
            for i, t in enumerate(timesteps):
                ...
                # predict the noise residual
                noise_pred = self.unet(
                    latent_model_input,
                    t,
                    encoder_hidden_states=prompt_embeds,
                    ...
                )[0]
        ...
        return StableDiffusionPipelineOutput(images=image, nsfw_content_detected=has_nsfw_concept)
```


$\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ ã‚’è¿‘ä¼¼ã™ã‚‹ãƒã‚¤ã‚ºæ¨å®šå™¨ãŒ

$$
\begin{align*}
\hat{\epsilon}_\theta (\mathbf{x}_t, c (s), t) = (1 + w) \epsilon_\theta (\mathbf{x}_t, c (p_+), t) - w \epsilon_\theta (\mathbf{x}_t, c (p_-), t)
\end{align*}
$$

ã§ã‚ã£ãŸã“ã¨ã‚’æ€ã„å‡ºã™ã¨ã€$\epsilon_\theta$ ã‚’å³è¾ºã§ 2 å›ä½¿ã£ã¦ã„ã‚‹ã®ã§ã€é–¢æ•°å‘¼ã³å‡ºã—ã¨ã—ã¦ 2 å›ã®é †ä¼æ’­ãŒç™ºç”Ÿã—ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚ã“ã‚Œã‚’ 1 å›ã§æ¸ˆã¾ã›ã‚‹ãŸã‚ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŸã¡ã‚’ `torch.cat` ã—ã¦ã„ã‚‹ã®ã§ã‚ã‚‹ã€‚ã¤ã¾ã‚Šã€æ•°å¼çš„ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã„ã‚‹:

$$
\begin{align*}
\epsilon_\theta \left(\mathbf{x}_t, \begin{pmatrix}c (p_-) \\ c (p_+)\end{pmatrix}, t \right)
\end{align*}
$$



`StableDiffusionPipeline` ã®å ´åˆã€U-Net ã¯ `UNet2DConditionModel` ã§ã‚ã‚‹ã®ã§æ¬¡ã«ã“ã‚Œã‚’è¦‹ã‚ˆã†ã€‚

# UNet2DConditionModel çªå…¥å‰å¾Œ

[UNet2DConditionModel](https://github.com/huggingface/diffusers/blob/v0.29.2/src/diffusers/models/unets/unet_2d_condition.py) ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã™ã‚‹ãŒã€ä¸Šè¨˜ã® `StableDiffusionPipeline.__call__` ã‚’è¦‹ç›´ã™ã¨ã€æ‰‹å‰ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç„¡æ¡ä»¶ã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã«ã‚ˆã‚‹ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã€å¾Œã‚ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé€£çµã•ã‚ŒãŸ `prompt_embeds` ãŒ `encoder_hidden_states` ã«æ¸¡ã•ã‚Œã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€`UNet2DConditionModel` ã¨ã—ã¦ã¯è‡ªèº«ã®ä½¿ã‚ã‚Œæ–¹ã®è©³ç´°ã‚’çŸ¥ã‚‰ãªã„é™ã‚Šã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŒºåˆ¥ãŒã¤ã‹ãªã„ã€‚å®Ÿéš›ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨çŸ¥ã‚‰ãªã„ã‚ˆã†ã§ã‚ã‚‹ã€‚


ã‚ˆã£ã¦ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®äº‹å¾Œå‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã®ã¯ U-Net ã‚’æŠœã‘ãŸä»¥ä¸‹ã®å‡¦ç†ã¨ãªã‚‹ã€‚`noise_pred_uncond` ã¨ã„ã†å¤‰æ•°ã§å—ã‘ã¦ã„ã‚‹ãŒã€å®Ÿéš›ã«ã¯ã“ã‚ŒãŒç„¡æ¡ä»¶ ($c = \empty$) ã¾ãŸã¯ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹ãƒã‚¤ã‚ºã§ã‚ã‚‹ã“ã¨ã«ãªã‚‹ã€‚

```python
                # perform guidance
                if self.do_classifier_free_guidance:
                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
                    noise_pred = noise_pred_uncond + self.guidance_scale * (noise_pred_text - noise_pred_uncond)
```

snippet ã®æœ€å¾Œã®ç·šå½¢çµåˆã¯ä»¥ä¸‹ã«å¯¾å¿œã™ã‚‹ã€‚ãªãŠ `self.guidance_scale` ãŒ $w$ ã®ã“ã¨ã§ã‚ã‚‹ã€‚ 

$$
\begin{align*}
\hat{\epsilon}_\theta (\mathbf{x}_t, c (s), t) = (1 + w) \epsilon_\theta (\mathbf{x}_t, c (p_+), t) - w \epsilon_\theta (\mathbf{x}_t, c (p_-), t)
\end{align*}
$$

æ®‹ã‚Šã®å‡¦ç†ã¯ã€Œåˆ†é¡å™¨ãªã—ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã€ã®é€šå¸¸ã®å‡¦ç†ã¨ãªã‚‹ã€‚

ã“ã‚Œã§ã“ã®è¨˜äº‹ã®ç›®çš„ã¯é”æˆã•ã‚ŒãŸã€‚

# Reverse Activation ã®ç¢ºèª

ç›®çš„é”æˆå¾Œã®ã‚ªãƒã‚±ã§ã‚ã‚‹ãŒã€arXiv:2406.02965 [Understanding the Impact of Negative Prompts: When and How Do They Take Effect?](https://arxiv.org/abs/2406.02965) ã®ä¸»å¼µã‚’æ€ã„å‡ºãã†:

1. é…å»¶åŠ¹æœ: ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå¯¾å¿œã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤ºã—ãŸå¾Œã€é…ã‚Œã¦åŠ¹æœãŒè¦³å¯Ÿã•ã‚Œã‚‹
1. ä¸­å’Œã«ã‚ˆã‚‹å‰Šé™¤: ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ½œåœ¨ç©ºé–“ã§ã®ç›¸äº’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã§ç”Ÿæˆã•ã‚ŒãŸæ¦‚å¿µã‚’æ‰“ã¡æ¶ˆã™
1. ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ—©æœŸé©ç”¨ã¯é€†ã«æœ›ã¾ãªã„ç”Ÿæˆ (â€œReverse Activationâ€) ã®å¯èƒ½æ€§

ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€é€†ã«æ„å›³ã—ãªã„ç”ŸæˆãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ã€‚

è«–æ–‡ã§ã‚„ãŸã‚‰çœ¼é¡æ¨ã—ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€ä»Šå›ã‚‚ãã‚Œã‚’ãƒã‚¿ã¨ã—ã¦è©¦ãã†ã€‚

## çœ¼é¡ã‚’ã‹ã‘ã•ã›ã‚‹

ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã€Œwearning glassesã€ã‚’è¿½åŠ ã—ã‚ˆã†:

```python
result = pipe(
    prompt="girl eating pizza wearning glasses",
    negative_prompt=None,
    ...
    num_inference_steps=50,
    ...
)
```

![](/images/dwd-stable-diffusion05/004.png =256x)

æ™®é€šã«æ„å›³é€šã‚Šã§ã‚ã‚‹ã€‚

## çœ¼é¡ã‚’ã‹ã‘ã•ã›ãªã„

**ãƒã‚¬ãƒ†ã‚£ãƒ–**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã€Œwearning glassesã€ã‚’æŒ‡å®šã—ã‚ˆã†:

```python
result = pipe(
    prompt="girl eating pizza",
    negative_prompt="wearning glasses",
    ...
    num_inference_steps=50,
    ...
)
```

![](/images/dwd-stable-diffusion05/005.png =256x)

ç¢ºã‹ã«è«–æ–‡ãŒè¨€ã£ã¦ã„ã‚‹ã‚ˆã†ãªã€Œç”»åƒã®æœ¬æ¥ã®æ§‹é€ ã‚’æ­ªã‚ã¦ã—ã¾ã†ã¨ã„ã†æ½œåœ¨çš„ãªå±é™ºæ€§ã€çš„ãªã‚‚ã®ãŒç›®å…ƒã«è¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ãªãƒ»ãƒ»ãƒ»ã€‚

## çœ¼é¡ã‚’ã‹ã‘ã•ã›ãªã„ã¯ãšãŒãƒ»ãƒ»ãƒ»ã‹ã‘ã¦ã„ã‚‹ï¼ï¼Ÿ

**ãƒã‚¬ãƒ†ã‚£ãƒ–**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã€Œwearning glassesã€ã‚’æŒ‡å®šã—ã¤ã¤ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã‚ˆã†:

```python
result = pipe(
    prompt="girl eating pizza",
    negative_prompt="wearning glasses",
    ...
    num_inference_steps=30,
    ...
)
```

![](/images/dwd-stable-diffusion05/006.png =256x)

ä¸å®Œå…¨ã§ã¯ã‚ã‚‹ãŒã€æœ¬æ¥ã¯æŠ‘åˆ¶ã™ã¹ãçœ¼é¡ã‚’ã‹ã‘ã¦ã—ã¾ã£ãŸã‚ˆã†ãªçµµã«ãªã£ã¦ã—ã¾ã£ãŸãƒ»ãƒ»ãƒ»ã€‚

# ã¾ã¨ã‚

- ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å¾“æ¥ã¯ç„¡æ¡ä»¶ã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã§ã‚ã£ãŸéƒ¨åˆ†ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã® embedding ã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ã§å¾—ã‚‰ã‚Œã‚‹ã€Œæœ›ã¾ãªã„ç”»åƒã®æŠ‘åˆ¶ã€ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚

$$
\begin{align*}
\hat{\epsilon}_\theta (\mathbf{x}_t, c (s), t) = (1 + w) \epsilon_\theta (\mathbf{x}_t, c (p_+), t) - w \epsilon_\theta (\mathbf{x}_t, c (p_-), t)
\end{align*}
$$

- æ—¢è£½ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†ã‚’ä½¿ã†å ´åˆã€â€œTextual Inversionâ€ ã¨å‘¼ã°ã‚Œã‚‹æŠ€è¡“ãŒåˆ©ç”¨ã§ãã‚‹ã“ã¨ã‚’è¦‹ãŸã€‚

- ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é›‘ãªé©ç”¨ã¯ã€æœ¬æ¥æœ›ã¾ãªã„ç”»åƒã‚’é€†ã«ç”Ÿæˆã—ã¦ã—ã¾ã†ã¨ã„ã† â€œReverse Activationâ€ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’è¦‹ãŸã€‚

â€œReverse Activationâ€ ã‚’å›é¿ã™ã‚‹ã«ã¯ `StableDiffusionPipeline` ã‚’æ”¹é€ ã—ã¦ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æŠ•å…¥ã‚’ã€Œã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¹ãƒ†ãƒƒãƒ—ã€ä»¥é™ã¾ã§é…ã‚‰ã›ã‚‹å¿…è¦ãŒã‚ã‚Šãã†ã ãŒã€ãã‚Œã¯ã¾ãŸåˆ¥ã®æ©Ÿä¼šã«ã€‚
